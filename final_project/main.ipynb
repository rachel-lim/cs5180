{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fc96a3e-7e5b-474a-a2da-2fea3b9d77c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "from envs import connectFourEnv, fourRoomsEnv, mazeEnv\n",
    "from networks import regular_net, rot_equi_net\n",
    "from utils import dqn_utils, plotting, schedules\n",
    "from utils.schedules import LinearSchedule\n",
    "from utils import dqn_utils\n",
    "from utils import plotting\n",
    "import memory_connectFour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d91d8f6e-376f-4919-8e0e-40f3969c0268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(params: dict, env_params: dict) -> Tuple[List[List[float]], List[float], List[float], List[int], dict]:\n",
    "    \"\"\"Run training and evaluation.\n",
    "\n",
    "    Args:\n",
    "        params: dict of training parameters\n",
    "        env_params: dict of environment params\n",
    "    Returns:\n",
    "        evals: list of list of evaluation returns during training, for each evaluation environment. For four rooms and connect\n",
    "        four, there is only one evaluation environment. For the maze there are two, one a duplicate of the training env and one\n",
    "        randomly rotated\n",
    "        returns: list of returns from training\n",
    "        losses: list of losses from training\n",
    "        lengths: list of episode lengths from training\n",
    "        saved_models: dict of saved copies of the model\n",
    "    \"\"\"\n",
    "    # create environments and models\n",
    "    if env_params[\"name\"] == \"maze\":\n",
    "        env = mazeEnv.MazeEnv(env_params[\"dim\"], env_params[\"seed\"])\n",
    "        eval_envs = [mazeEnv.MazeEnv(env_params[\"dim\"], env_params[\"eval_seed\"], env.grid), # copy of env\n",
    "                    mazeEnv.MazeEnv(env_params[\"dim\"], env_params[\"eval_seed\"], env.grid, np.random.choice([1,2,3]))] # rotated env\n",
    "        dqn_model = regular_net.CNN() if params[\"model\"] == \"regular\" else rot_equi_net.EquiCNN()\n",
    "        dqn_target = regular_net.CNN() if params[\"model\"] == \"regular\" else rot_equi_net.EquiCNN()\n",
    "    \n",
    "    elif env_params[\"name\"] == \"fourrooms\":\n",
    "        env = fourRoomsEnv.FourRoomsEnv(env_params[\"seed\"])\n",
    "        eval_envs = [fourRoomsEnv.FourRoomsEnv(env_params[\"eval_seed\"])]\n",
    "        dqn_model = regular_net.CNN(2) if params[\"model\"] == \"regular\" else rot_equi_net.EquiCNN(2)\n",
    "        dqn_target = regular_net.CNN(2) if params[\"model\"] == \"regular\" else rot_equi_net.EquiCNN(2)\n",
    "    elif env_params[\"name\"] == \"connectfour\":\n",
    "        env = connectFourEnv.ConnectFourEnv(env_params[\"seed\"])\n",
    "        eval_envs = [connectFourEnv.ConnectFourEnv(env_params[\"eval_seed\"])]\n",
    "\n",
    "    # train on gpu if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "    # create optimizer\n",
    "    optimizer = torch.optim.Adam(dqn_model.parameters(), lr=1e-3)\n",
    "\n",
    "    # epsilon function\n",
    "    exploration = LinearSchedule(1.0, 0.1, params[\"num_steps\"])\n",
    "    \n",
    "    # create and prepopulate memory\n",
    "    memory = memory_connectFour.ReplayMemory(params[\"replay_size\"], env.grid.shape, device)\n",
    "    memory.populate(env, params[\"replay_prepopulate_steps\"])\n",
    "    \n",
    "    # collect results\n",
    "    rewards = []\n",
    "    returns = []  # returns from training\n",
    "    lengths = []\n",
    "    losses = []\n",
    "    evals = []  # returns from evaluation runs\n",
    "    \n",
    "    # for storing model\n",
    "    t_saves = np.linspace(0, params[\"num_steps\"], params[\"num_saves\"] - 1, endpoint=False)\n",
    "    saved_models = {}\n",
    "    \n",
    "    i_episode = 0  # index of current episode\n",
    "    t_episode = 0  # time step\n",
    "\n",
    "    # reset everything\n",
    "    obs = env.reset()\n",
    "\n",
    "    # run training loop\n",
    "    pbar = tqdm.trange(params[\"num_steps\"])\n",
    "    for t_total in pbar:\n",
    "    \n",
    "        if t_total in t_saves:\n",
    "            model_name = f'{100 * t_total / params[\"num_steps\"]:04.1f}'.replace('.', '_')\n",
    "            saved_models[model_name] = copy.deepcopy(dqn_model)\n",
    "    \n",
    "        # get action using e-greedy\n",
    "        eps = exploration.value(t_total)  # get current epsilon value\n",
    "        if np.random.rand() < eps:\n",
    "            action = np.random.choice(env.action_space)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                q_values = dqn_model(torch.tensor(obs, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device))  # add dim to observation\n",
    "                max_q_idx = torch.where(q_values == q_values.max())[0]\n",
    "                action = np.random.choice(max_q_idx.tolist())\n",
    "            \n",
    "        # step forward env\n",
    "        next_obs, reward, done = env.step(action)\n",
    "        rewards.append(reward)\n",
    "    \n",
    "        # add transition to memory\n",
    "        memory.add(obs, action, reward, next_obs, done)\n",
    "\n",
    "        # get batch and train every 4 time steps\n",
    "        if t_total%4 == 0:\n",
    "            batch = memory.sample(params[\"batch_size\"])\n",
    "            loss = dqn_utils.train_dqn_batch(optimizer, batch, dqn_model, dqn_target, params[\"gamma\"])\n",
    "            losses.append(loss)\n",
    "\n",
    "        # update target every 10,000 time steps\n",
    "        if t_total%10000 == 0:\n",
    "            dqn_target.load_state_dict(dqn_model.state_dict())\n",
    "\n",
    "        # evaluate model every 1,000 steps\n",
    "        if t_total%1000 == 0:\n",
    "            evals.append([dqn_utils.evaluate(dqn_model, eval_env, device) for eval_env in eval_envs])\n",
    "    \n",
    "        if done:\n",
    "            G = 0\n",
    "            for r in rewards[::-1]:\n",
    "                G = params[\"gamma\"] * G + r\n",
    "    \n",
    "            returns.append(G)\n",
    "            lengths.append(t_episode)\n",
    "    \n",
    "            pbar.set_description(\n",
    "                f'Episode: {i_episode} | Steps: {t_episode + 1} | Return: {G:5.2f} | Epsilon: {eps:4.2f}'\n",
    "            )\n",
    "    \n",
    "            # reset\n",
    "            t_episode = 0\n",
    "            i_episode += 1\n",
    "            rewards = []\n",
    "            obs = env.reset()\n",
    "            \n",
    "        else:\n",
    "            obs = np.copy(next_obs)\n",
    "            t_episode += 1\n",
    "    \n",
    "    saved_models['100_0'] = copy.deepcopy(dqn_model)\n",
    "\n",
    "    return evals, returns, losses, lengths, saved_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97c2e91f-c6c5-488c-aea5-107722b47aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode: 1 | Steps: 297 | Return: -94.38 | Epsilon: 0.67: 100%|â–ˆ| 1000/1000 [00:\n"
     ]
    }
   ],
   "source": [
    "params = {\"num_steps\": 1_000,\n",
    "          \"num_saves\": 5,\n",
    "          \"replay_size\": 200_000,\n",
    "          \"replay_prepopulate_steps\": 50_000,\n",
    "          \"batch_size\": 64,\n",
    "          \"gamma\": 0.99,\n",
    "          \"model\": \"regular\"} # equi or regular \n",
    "\n",
    "env_params = {\"name\": \"fourrooms\", # [\"maze\", \"fourrooms\", \"connectfour\"]\n",
    "              \"dim\": 3,  # only needed for maze\n",
    "              \"seed\": None,\n",
    "              \"eval_seed\": None,\n",
    "             }\n",
    "evals, returns, losses, lengths, saved_models = train_and_eval(params, env_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
